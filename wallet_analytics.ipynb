{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f8cb9cf9",
      "metadata": {},
      "source": [
        "Phase 0 — Orientation & Tooling (Week 1)\n",
        "\n",
        "* **Local dev environment ready**\n",
        "    Repo folder: /Software_development/Python/projects/wallet_analytics\n",
        "* **API key obtained**\n",
        "    Alchemy API key: .env\n",
        "* **Git repo initialized**\n",
        "    https://github.com/Dev-Uchiha/wallet_analytics.git\n",
        "\n",
        "\n",
        "To start, i created a repository folder on my laptop called wallet_analytics where everything related to the project can be stored.\n",
        "I then installed a python package manager called \"uv\". A package manager is a python (programming language) toolkit which allows the user to install all the needed tools (packages of code) to create a project. For e.g to do maths using python, i would need to install \"numpy\" which will already have all the code needed to do calculations.\n",
        "I chose uv specifically because it is much faster at downloading packages than the standard package manager \"pip\" and it is also what we use at work.\n",
        "I then used uv to create a virtual environment inside the wallet_analytics folder. This virtual environment is the place where all the installed tools(code) related to the projects will reside. Each project should have its own virtual environment for code cleanliness.\n",
        "\n",
        "I then created an account with Alchemy to get their API key (An API is a way for one software to speak to another). This key allows me to get data about Ethereum wallets from the Alchemy website.\n",
        "\n",
        "Lastly, I installed \"git\", which allows me to keep track of the different changes i make to my code. I also connected it to \"github\" so that i can store my code on the github website."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3f42abd",
      "metadata": {},
      "source": [
        "Phase 1 — Raw On-Chain Data Ingestion (Weeks 2–3)\n",
        "* Normal transactions\n",
        "* ERC-20 token transfers\n",
        "\n",
        "**Deliverable**\n",
        "\n",
        "* Script that pulls data for 1 wallet\n",
        "* Raw tables saved locally\n",
        "* Re-runnable without manual edits\n",
        "\n",
        "\n",
        "I then created various functions (blocks of code that have a spefic purpose), to return the last 10 transactions from vitalik buterins eth wallet, displaying the transaction hash (a unique transaction id), eth amount and data. This can be verified by putting his wallet address in an eth blockchain explorer (a website which allows you to track wallet data) to see if the last 10 transactions are the same. \n",
        "\n",
        "https://etherscan.io/address/0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045\n",
        "\n",
        "The next step was to bring back all the relevant wallet data and save them locally as .csv files. \n",
        "This included:\n",
        "\n",
        "**transactions**\n",
        "tx_hash\n",
        "block_number\n",
        "timestamp\n",
        "from_address\n",
        "to_address\n",
        "value_eth\n",
        "gas_used\n",
        "gas_price\n",
        "status\n",
        "\n",
        "**token_transfers**\n",
        "tx_hash\n",
        "token_symbol\n",
        "token_contract\n",
        "from_address\n",
        "to_address\n",
        "value\n",
        "timestamp\n",
        "\n",
        "The differences between transactions and token transfers are:\n",
        "    - a transaction moves a value of eth (the base asset) from one wallet to another (e.g sending someone 5 eth). It initiates an execution and shows what was sent and who sent it.\n",
        "    - a token transfer changes the ownership of a token from one wallet to another (e.g sending someone an nft). It shows what did the contract say happened. \n",
        "    - all token transfers happen within transactions, but a token transfer isnt needed for a transaction\n",
        "    - transactions are recorded in the transaction object() but token transfers are recorded in the logs (a description of what happened in the contract)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf0a5f25",
      "metadata": {},
      "source": [
        "## Phase 2 — Wallet-Level Analytics (Weeks 4–5)\n",
        "\n",
        "\n",
        "### Derived Metrics (Core)\n",
        "\n",
        "Per wallet:\n",
        "\n",
        "* Total ETH received / sent\n",
        "* Net ETH balance (from txs, not live balance)\n",
        "* Gas spent (ETH)\n",
        "* Transaction count\n",
        "* Active days\n",
        "* First / last activity\n",
        "\n",
        "Token-level:\n",
        "\n",
        "* Tokens interacted with\n",
        "* Net token inflow/outflow\n",
        "* Frequency by token\n",
        "\n",
        "### Behavioral Metrics (Differentiator)\n",
        "\n",
        "* Avg tx size\n",
        "* Tx frequency over time\n",
        "* % outgoing vs incoming\n",
        "* Gas per transaction trend\n",
        "* Dormant periods\n",
        "\n",
        "### Output Tables\n",
        "\n",
        "**wallet_summary**\n",
        "\n",
        "```\n",
        "wallet\n",
        "first_tx_date\n",
        "last_tx_date\n",
        "tx_count\n",
        "total_eth_sent\n",
        "total_eth_received\n",
        "net_eth\n",
        "total_gas_spent\n",
        "current_eth_balance\n",
        "```\n",
        "\n",
        "**wallet_activity**\n",
        "\n",
        "```\n",
        "wallet\n",
        "period\n",
        "tx_count\n",
        "eth_sent\n",
        "eth_received\n",
        "gas_spent\n",
        "```\n",
        "\n",
        "**Deliverable**\n",
        "\n",
        "* Clean analytical tables\n",
        "* Documented metric definitions\n",
        "* Deterministic transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23dd74a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Creating the virtual environment\n",
        "\n",
        "cd users/name/project\n",
        "uv venv .venv        # once\n",
        "uv sync              # whenever deps change\n",
        "source .venv/bin/activate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5e1f5bd4",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Imports\n",
        "\n",
        "# Return the last 10 transactions from an ethereum wallet\n",
        "# Return the most relevant data headers\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from dotenv import load_dotenv\n",
        "import psycopg2\n",
        "from psycopg2 import sql\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d300664e",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Config (API key, DB config, constants)\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "ALCHEMY_API_KEY = os.getenv(\"ALCHEMY_API_KEY\")\n",
        "ALCHEMY_BASE_URL = \"https://eth-mainnet.g.alchemy.com/v2\"\n",
        "OUTPUT_DIR = \"output\"\n",
        "CSV_COUNT = 100\n",
        "\n",
        "\n",
        "DB_CONFIG = {\n",
        "    \"dbname\": \"wallet_analytics\",\n",
        "    \"user\": os.getenv(\"DB_USER\"),\n",
        "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
        "    \"host\": \"localhost\",\n",
        "    \"port\": 5432\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "417efd30",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected to PostgreSQL successfully\n",
            "Tables created successfully\n"
          ]
        }
      ],
      "source": [
        "#DB connection and create_tables()\n",
        "def get_db_connection():\n",
        "    \"\"\"Create and return a connection to the PostgreSQL database.\"\"\"\n",
        "    return psycopg2.connect(**DB_CONFIG)\n",
        "\n",
        "# Test the connection\n",
        "try:\n",
        "    conn = get_db_connection()\n",
        "    print(\"Connected to PostgreSQL successfully\")\n",
        "    conn.close()\n",
        "except Exception as e:\n",
        "    print(f\"Connection failed: {e}\")\n",
        "    \n",
        "def create_tables():\n",
        "    \"\"\"Create the wallet_summary and wallet_activity tables if they don't already exist.\"\"\"\n",
        "    conn = get_db_connection()\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS wallet_summary (\n",
        "            wallet TEXT,\n",
        "            first_tx_date DATE,\n",
        "            last_tx_date DATE,\n",
        "            tx_count BIGINT,\n",
        "            total_eth_sent DOUBLE PRECISION,\n",
        "            total_eth_received DOUBLE PRECISION,\n",
        "            net_eth DOUBLE PRECISION,\n",
        "            total_gas_spent DOUBLE PRECISION,\n",
        "            current_eth_balance DOUBLE PRECISION\n",
        "        );\n",
        "    \"\"\")\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS wallet_activity (\n",
        "            wallet TEXT,\n",
        "            period DATE,\n",
        "            tx_count BIGINT,\n",
        "            eth_sent DOUBLE PRECISION,\n",
        "            eth_received DOUBLE PRECISION,\n",
        "            gas_spent DOUBLE PRECISION\n",
        "        );\n",
        "    \"\"\")\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS token_transfers (\n",
        "        wallet TEXT,\n",
        "        tx_hash TEXT,\n",
        "        token_symbol TEXT,\n",
        "        token_contract TEXT,\n",
        "        from_address TEXT,\n",
        "        to_address TEXT,\n",
        "        value DOUBLE PRECISION,\n",
        "        timestamp TIMESTAMP\n",
        "    );\n",
        "    \"\"\")\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS transactions (\n",
        "        tx_hash TEXT,\n",
        "        block_number BIGINT,\n",
        "        timestamp TIMESTAMP,\n",
        "        from_address TEXT,\n",
        "        to_address TEXT,\n",
        "        value_eth DOUBLE PRECISION,\n",
        "        gas_used BIGINT,\n",
        "        gas_price BIGINT,\n",
        "        status TEXT,\n",
        "        tx_type TEXT,\n",
        "        wallet TEXT\n",
        "    );\n",
        "\"\"\")\n",
        "\n",
        "    conn.commit()\n",
        "    cursor.close()\n",
        "    conn.close()\n",
        "    print(\"Tables created successfully\")\n",
        "\n",
        "create_tables()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "34175556",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Alchemy fetch functions\n",
        "\n",
        "def get_alchemy_json(method, params):\n",
        "    \"\"\"Make a request to Alchemy JSON-RPC.\"\"\"\n",
        "    url = f\"{ALCHEMY_BASE_URL}/{ALCHEMY_API_KEY}\"\n",
        "    payload = {\"id\": 1, \"jsonrpc\": \"2.0\", \"method\": method, \"params\": params}\n",
        "\n",
        "    r = requests.post(url, json=payload, headers={\"Content-Type\": \"application/json\"})\n",
        "    r.raise_for_status()\n",
        "\n",
        "    data = r.json()\n",
        "    if \"error\" in data:\n",
        "        raise Exception(f\"Alchemy API error: {data['error']}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def get_eth_balance(address):\n",
        "    \"\"\"Return ETH balance for an address (in ETH).\"\"\"\n",
        "    data = get_alchemy_json(\"eth_getBalance\", [address, \"latest\"])\n",
        "    balance_wei = int(data[\"result\"], 16)\n",
        "    return balance_wei / 10**18\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4c94c692",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transactions/token transfers  functions\n",
        "\n",
        "def _fetch_external_transfers(address, max_count):\n",
        "    \"\"\"Fetch up to max_count external (ETH) transfers for address; reuses get_alchemy_json from above.\"\"\"\n",
        "    base_params = {\n",
        "        \"fromBlock\": \"0x0\",\n",
        "        \"toBlock\": \"latest\",\n",
        "        \"category\": [\"external\"],\n",
        "        \"maxCount\": hex(max_count),\n",
        "        \"excludeZeroValue\": False,\n",
        "        \"withMetadata\": True,\n",
        "        \"order\": \"desc\",\n",
        "    }\n",
        "    all_txs = []\n",
        "    for key, val in [(\"toAddress\", address), (\"fromAddress\", address)]:\n",
        "        p = {**base_params, key: val}\n",
        "        data = get_alchemy_json(\"alchemy_getAssetTransfers\", [p])\n",
        "        all_txs.extend(data.get(\"result\", {}).get(\"transfers\", []))\n",
        "        time.sleep(0.1)\n",
        "    df = pd.DataFrame(all_txs)\n",
        "    if df.empty:\n",
        "        return df\n",
        "    if \"hash\" in df.columns:\n",
        "        df = df.drop_duplicates(subset=[\"hash\"], keep=\"first\")\n",
        "    if \"blockNum\" in df.columns:\n",
        "        df[\"_bn\"] = df[\"blockNum\"].apply(\n",
        "            lambda x: int(x, 16) if isinstance(x, str) and x.startswith(\"0x\") else -1\n",
        "        )\n",
        "        df = df.sort_values(\"_bn\", ascending=False).drop(columns=[\"_bn\"])\n",
        "    return df.head(max_count).reset_index(drop=True)\n",
        "\n",
        "\n",
        "def get_transactions(address):\n",
        "    \"\"\"\n",
        "    Return normal (external ETH) transactions as a DataFrame with schema:\n",
        "    tx_hash, block_number, timestamp, from_address, to_address, value_eth, gas_used, gas_price, status.\n",
        "    Displays last 10; contains last 100.\n",
        "    \"\"\"\n",
        "    raw = _fetch_external_transfers(address, CSV_COUNT)\n",
        "    if raw.empty:\n",
        "        return pd.DataFrame(columns=[\n",
        "            \"tx_hash\", \"block_number\", \"timestamp\", \"from_address\", \"to_address\",\n",
        "            \"value_eth\", \"gas_used\", \"gas_price\", \"status\",\n",
        "        ])\n",
        "\n",
        "    rows = []\n",
        "    for _, row in raw.iterrows():\n",
        "        tx_hash = row.get(\"hash\", \"\")\n",
        "        block_hex = row.get(\"blockNum\", \"0x0\")\n",
        "        block_number = int(block_hex, 16) if isinstance(block_hex, str) and block_hex.startswith(\"0x\") else 0\n",
        "        meta = row.get(\"metadata\") or {}\n",
        "        timestamp = meta.get(\"blockTimestamp\", \"\")\n",
        "        from_addr = row.get(\"from\", \"\")\n",
        "        to_addr = row.get(\"to\", \"\")\n",
        "        val = row.get(\"value\")\n",
        "        if val is None:\n",
        "            value_wei = 0\n",
        "        elif isinstance(val, str) and str(val).startswith(\"0x\"):\n",
        "            value_wei = int(val, 16)\n",
        "        else:\n",
        "            value_wei = int(val) if val is not None else 0\n",
        "        value_eth = value_wei / 10**18\n",
        "\n",
        "        gas_used, gas_price, status = None, None, None\n",
        "        try:\n",
        "            tx_data = get_alchemy_json(\"eth_getTransactionByHash\", [tx_hash])\n",
        "            receipt = get_alchemy_json(\"eth_getTransactionReceipt\", [tx_hash])\n",
        "            time.sleep(0.05)\n",
        "            if tx_data.get(\"result\"):\n",
        "                gas_price = int(tx_data[\"result\"].get(\"gasPrice\", \"0x0\"), 16)\n",
        "            if receipt.get(\"result\"):\n",
        "                gas_used = int(receipt[\"result\"].get(\"gasUsed\", \"0x0\"), 16)\n",
        "                status = \"success\" if int(receipt[\"result\"].get(\"status\", \"0x0\"), 16) == 1 else \"failed\"\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        rows.append({\n",
        "            \"tx_hash\": tx_hash,\n",
        "            \"block_number\": block_number,\n",
        "            \"timestamp\": timestamp,\n",
        "            \"from_address\": from_addr,\n",
        "            \"to_address\": to_addr,\n",
        "            \"value_eth\": value_eth,\n",
        "            \"gas_used\": gas_used,\n",
        "            \"gas_price\": gas_price,\n",
        "            \"status\": status,\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    return df\n",
        "\n",
        "\n",
        "def _fetch_token_transfers(address, max_count):\n",
        "    \"\"\"Fetch up to max_count ERC-20 token transfers for address.\"\"\"\n",
        "    base_params = {\n",
        "        \"fromBlock\": \"0x0\",\n",
        "        \"toBlock\": \"latest\",\n",
        "        \"category\": [\"erc20\"],\n",
        "        \"maxCount\": hex(max_count),\n",
        "        \"excludeZeroValue\": False,\n",
        "        \"withMetadata\": True,\n",
        "        \"order\": \"desc\",\n",
        "    }\n",
        "    all_txs = []\n",
        "    for key, val in [(\"toAddress\", address), (\"fromAddress\", address)]:\n",
        "        p = {**base_params, key: val}\n",
        "        data = get_alchemy_json(\"alchemy_getAssetTransfers\", [p])\n",
        "        all_txs.extend(data.get(\"result\", {}).get(\"transfers\", []))\n",
        "        time.sleep(0.1)\n",
        "    df = pd.DataFrame(all_txs)\n",
        "    if df.empty:\n",
        "        return df\n",
        "    if \"hash\" in df.columns:\n",
        "        df = df.drop_duplicates(subset=[\"hash\"], keep=\"first\")\n",
        "    if \"blockNum\" in df.columns:\n",
        "        df[\"_bn\"] = df[\"blockNum\"].apply(\n",
        "            lambda x: int(x, 16) if isinstance(x, str) and x.startswith(\"0x\") else -1\n",
        "        )\n",
        "        df = df.sort_values(\"_bn\", ascending=False).drop(columns=[\"_bn\"])\n",
        "    return df.head(max_count).reset_index(drop=True)\n",
        "\n",
        "\n",
        "def get_token_transfers(address):\n",
        "    \"\"\"\n",
        "    Return ERC-20 token transfers as a DataFrame with schema:\n",
        "    tx_hash, token_symbol, token_contract, from_address, to_address, value, timestamp.\n",
        "    Displays last 10; contains last 100.\n",
        "    \"\"\"\n",
        "    raw = _fetch_token_transfers(address, CSV_COUNT)\n",
        "    if raw.empty:\n",
        "        return pd.DataFrame(columns=[\n",
        "            \"tx_hash\", \"token_symbol\", \"token_contract\", \"from_address\", \"to_address\",\n",
        "            \"value\", \"timestamp\",\n",
        "        ])\n",
        "\n",
        "    rows = []\n",
        "    for _, row in raw.iterrows():\n",
        "        meta = row.get(\"metadata\") or {}\n",
        "        raw_contract = row.get(\"rawContract\") or {}\n",
        "        token_contract = raw_contract.get(\"address\", \"\") or \"\"\n",
        "        # Alchemy may return 'asset' as symbol (e.g. \"USDC\"); fallback to contract or \"N/A\"\n",
        "        token_symbol = row.get(\"asset\") or row.get(\"symbol\") or token_contract or \"N/A\"\n",
        "        if isinstance(token_symbol, dict):\n",
        "            token_symbol = token_symbol.get(\"symbol\", \"N/A\") or \"N/A\"\n",
        "        value_raw = row.get(\"value\")\n",
        "        if value_raw is None:\n",
        "            value = None\n",
        "        elif isinstance(value_raw, (int, float)):\n",
        "            value = float(value_raw)\n",
        "        else:\n",
        "            try:\n",
        "                value = int(str(value_raw), 16) if str(value_raw).startswith(\"0x\") else float(value_raw)\n",
        "            except (ValueError, TypeError):\n",
        "                value = value_raw\n",
        "        rows.append({\n",
        "            \"tx_hash\": row.get(\"hash\", \"\"),\n",
        "            \"token_symbol\": str(token_symbol),\n",
        "            \"token_contract\": token_contract,\n",
        "            \"from_address\": row.get(\"from\", \"\"),\n",
        "            \"to_address\": row.get(\"to\", \"\"),\n",
        "            \"value\": value,\n",
        "            \"timestamp\": meta.get(\"blockTimestamp\", \"\"),\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a42254af",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analytics/metrics functions\n",
        "\n",
        "def _parse_ts(ts):\n",
        "    \"\"\"Parse timestamp string to date for grouping. Handles ISO and common formats.\"\"\"\n",
        "    if ts is None or (isinstance(ts, float) and pd.isna(ts)):\n",
        "        return None\n",
        "    s = str(ts).strip()\n",
        "    if not s:\n",
        "        return None\n",
        "    try:\n",
        "        if \"T\" in s:\n",
        "            return datetime.fromisoformat(s.replace(\"Z\", \"+00:00\")).date()\n",
        "        return datetime.strptime(s[:10], \"%Y-%m-%d\").date()\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def _gas_spent_eth(row):\n",
        "    \"\"\"Gas spent in ETH from gas_used and gas_price (wei).\"\"\"\n",
        "    gu, gp = row.get(\"gas_used\"), row.get(\"gas_price\")\n",
        "    if pd.isna(gu) or pd.isna(gp) or gu is None or gp is None:\n",
        "        return 0.0\n",
        "    try:\n",
        "        return (int(gu) * int(gp)) / 1e18\n",
        "    except (TypeError, ValueError):\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "# --- Core metric functions (from transactions DataFrame for one wallet) ---\n",
        "\n",
        "def total_eth_sent(tx_df, wallet_address):\n",
        "    \"\"\"Total ETH sent by wallet (outgoing value_eth where from_address == wallet).\"\"\"\n",
        "    if tx_df.empty or \"from_address\" not in tx_df.columns:\n",
        "        return 0.0\n",
        "    mask = tx_df[\"from_address\"].str.lower() == wallet_address.lower()\n",
        "    return float(tx_df.loc[mask, \"value_eth\"].sum())\n",
        "\n",
        "\n",
        "def total_eth_received(tx_df, wallet_address):\n",
        "    \"\"\"Total ETH received by wallet (incoming value_eth where to_address == wallet).\"\"\"\n",
        "    if tx_df.empty or \"to_address\" not in tx_df.columns:\n",
        "        return 0.0\n",
        "    mask = tx_df[\"to_address\"].str.lower() == wallet_address.lower()\n",
        "    return float(tx_df.loc[mask, \"value_eth\"].sum())\n",
        "\n",
        "\n",
        "def net_eth_from_txs(tx_df, wallet_address):\n",
        "    \"\"\"Net ETH from transactions (received - sent).\"\"\"\n",
        "    return total_eth_received(tx_df, wallet_address) - total_eth_sent(tx_df, wallet_address)\n",
        "\n",
        "\n",
        "def total_gas_spent_eth(tx_df):\n",
        "    \"\"\"Total gas spent in ETH across all transactions.\"\"\"\n",
        "    if tx_df.empty:\n",
        "        return 0.0\n",
        "    return float(tx_df.apply(_gas_spent_eth, axis=1).sum())\n",
        "\n",
        "\n",
        "def first_last_activity_dates(tx_df):\n",
        "    \"\"\"Return (first_tx_date, last_tx_date) as date objects or (None, None).\"\"\"\n",
        "    if tx_df.empty or \"timestamp\" not in tx_df.columns:\n",
        "        return None, None\n",
        "    dates = tx_df[\"timestamp\"].apply(_parse_ts).dropna()\n",
        "    if dates.empty:\n",
        "        return None, None\n",
        "    return dates.min(), dates.max()\n",
        "\n",
        "\n",
        "def active_days_count(tx_df):\n",
        "    \"\"\"Number of distinct days with at least one transaction.\"\"\"\n",
        "    if tx_df.empty or \"timestamp\" not in tx_df.columns:\n",
        "        return 0\n",
        "    dates = tx_df[\"timestamp\"].apply(_parse_ts).dropna()\n",
        "    return int(dates.nunique())\n",
        "\n",
        "\n",
        "# --- Tableau output tables ---\n",
        "\n",
        "def get_wallet_summary_table(address):\n",
        "    \"\"\"\n",
        "    Build wallet_summary table for one ETH wallet. Uses get_transactions() from previous cells.\n",
        "\n",
        "    Columns: wallet, first_tx_date, last_tx_date, tx_count, total_eth_sent, total_eth_received, net_eth, total_gas_spent, current_eth_balance\n",
        "    \"\"\"\n",
        "    try:\n",
        "        get_transactions\n",
        "    except NameError:\n",
        "        raise NameError(\n",
        "            \"get_transactions is not defined. Run the Phase 1 cell \"\n",
        "            \"'Transactions and token_transfers in project schema' first.\"\n",
        "        )\n",
        "    tx_df = get_transactions(address)\n",
        "    wallet = address\n",
        "    current_balance = get_eth_balance(address)\n",
        "\n",
        "    if tx_df.empty:\n",
        "\n",
        "        row = {\n",
        "            \"wallet\": wallet,\n",
        "            \"first_tx_date\": None,\n",
        "            \"last_tx_date\": None,\n",
        "            \"tx_count\": 0,\n",
        "            \"total_eth_sent\": 0.0,\n",
        "            \"total_eth_received\": 0.0,\n",
        "            \"net_eth\": 0.0,\n",
        "            \"total_gas_spent\": 0.0,\n",
        "            \"current_eth_balance\": current_balance,\n",
        "        }\n",
        "    else:\n",
        "        first_d, last_d = first_last_activity_dates(tx_df)\n",
        "\n",
        "        row = {\n",
        "            \"wallet\": wallet,\n",
        "            \"first_tx_date\": first_d,\n",
        "            \"last_tx_date\": last_d,\n",
        "            \"tx_count\": len(tx_df),\n",
        "            \"total_eth_sent\": total_eth_sent(tx_df, address),\n",
        "            \"total_eth_received\": total_eth_received(tx_df, address),\n",
        "            \"net_eth\": net_eth_from_txs(tx_df, address),\n",
        "            \"total_gas_spent\": total_gas_spent_eth(tx_df),\n",
        "            \"current_eth_balance\": current_balance,\n",
        "        }\n",
        "\n",
        "    summary_df = pd.DataFrame([row])\n",
        "    return summary_df\n",
        "\n",
        "\n",
        "def get_wallet_activity_table(address, start_date=None, end_date=None):\n",
        "    \"\"\"\n",
        "    Build wallet_activity table with daily aggregates. For Tableau.\n",
        "\n",
        "    Columns: wallet, period (date), tx_count, eth_sent, eth_received, gas_spent.\n",
        "\n",
        "    - start_date / end_date: optional date-like (str YYYY-MM-DD or date). If both None, returns daily activity for full history (default).\n",
        "    - If provided, only transactions within [start_date, end_date] are included, still aggregated by day.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        get_transactions\n",
        "    except NameError:\n",
        "        raise NameError(\n",
        "            \"get_transactions is not defined. Run the Phase 1 cell \"\n",
        "            \"'Transactions and token_transfers in project schema' first.\"\n",
        "        )\n",
        "    tx_df = get_transactions(address)\n",
        "    wallet = address\n",
        "\n",
        "    if tx_df.empty:\n",
        "        out = pd.DataFrame(columns=[\"wallet\", \"period\", \"tx_count\", \"eth_sent\", \"eth_received\", \"gas_spent\"])\n",
        "        return out\n",
        "\n",
        "    tx_df = tx_df.copy()\n",
        "    tx_df[\"_date\"] = tx_df[\"timestamp\"].apply(_parse_ts)\n",
        "    tx_df = tx_df.dropna(subset=[\"_date\"])\n",
        "\n",
        "    if start_date is not None or end_date is not None:\n",
        "        if isinstance(start_date, str):\n",
        "            start_date = datetime.strptime(start_date[:10], \"%Y-%m-%d\").date()\n",
        "        if isinstance(end_date, str):\n",
        "            end_date = datetime.strptime(end_date[:10], \"%Y-%m-%d\").date()\n",
        "        if start_date is not None:\n",
        "            tx_df = tx_df[tx_df[\"_date\"] >= start_date]\n",
        "        if end_date is not None:\n",
        "            tx_df = tx_df[tx_df[\"_date\"] <= end_date]\n",
        "\n",
        "    if tx_df.empty:\n",
        "        out = pd.DataFrame(columns=[\"wallet\", \"period\", \"tx_count\", \"eth_sent\", \"eth_received\", \"gas_spent\"])\n",
        "        return out\n",
        "\n",
        "    tx_df[\"_gas_eth\"] = tx_df.apply(_gas_spent_eth, axis=1)\n",
        "    addr_lower = address.lower()\n",
        "\n",
        "    def eth_sent_for_group(g):\n",
        "        return g.loc[g[\"from_address\"].str.lower() == addr_lower, \"value_eth\"].sum()\n",
        "\n",
        "    def eth_received_for_group(g):\n",
        "        return g.loc[g[\"to_address\"].str.lower() == addr_lower, \"value_eth\"].sum()\n",
        "\n",
        "    by_date = tx_df.groupby(\"_date\", as_index=False).agg(\n",
        "        tx_count=(\"tx_hash\", \"count\"),\n",
        "        gas_spent=(\"_gas_eth\", \"sum\"),\n",
        "    )\n",
        "    sent_by_date = tx_df.groupby(\"_date\").apply(eth_sent_for_group)\n",
        "    received_by_date = tx_df.groupby(\"_date\").apply(eth_received_for_group)\n",
        "    by_date[\"eth_sent\"] = by_date[\"_date\"].map(sent_by_date).fillna(0)\n",
        "    by_date[\"eth_received\"] = by_date[\"_date\"].map(received_by_date).fillna(0)\n",
        "    by_date[\"wallet\"] = wallet\n",
        "    by_date = by_date.rename(columns={\"_date\": \"period\"})\n",
        "    by_date = by_date[[\"wallet\", \"period\", \"tx_count\", \"eth_sent\", \"eth_received\", \"gas_spent\"]]\n",
        "\n",
        "    return by_date\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "12d43898",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Export to CSV\n",
        "\n",
        "def export_to_csv(summary_df, activity_df, token_df):\n",
        "    \"\"\"Export wallet_summary, wallet_activity and token_transfers DataFrames to CSV for Tableau Public.\"\"\"\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    summary_path = os.path.join(OUTPUT_DIR, f\"wallet_summary_{date_str}.csv\")\n",
        "    activity_path = os.path.join(OUTPUT_DIR, f\"wallet_activity_{date_str}.csv\")\n",
        "    token_path = os.path.join(OUTPUT_DIR, f\"token_transfers_{date_str}.csv\")\n",
        "\n",
        "    summary_df.to_csv(summary_path, index=False)\n",
        "    activity_df.to_csv(activity_path, index=False)\n",
        "    token_df.to_csv(token_path, index=False)\n",
        "\n",
        "    print(f\"Exported summary to {summary_path}\")\n",
        "    print(f\"Exported activity to {activity_path}\")\n",
        "    print(f\"Exported token transfers to {token_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e859ff40",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running pipeline for 0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/bv/b5k07hp50fnfylh6_nb6v9zr0000gn/T/ipykernel_18382/3391460142.py:182: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sent_by_date = tx_df.groupby(\"_date\").apply(eth_sent_for_group)\n",
            "/var/folders/bv/b5k07hp50fnfylh6_nb6v9zr0000gn/T/ipykernel_18382/3391460142.py:183: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  received_by_date = tx_df.groupby(\"_date\").apply(eth_received_for_group)\n"
          ]
        },
        {
          "ename": "SyntaxError",
          "evalue": "syntax error at or near \"h\"\nLINE 5:                 h,\n                        ^\n",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mSyntaxError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 86\u001b[39m\n\u001b[32m     83\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPipeline complete.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Run it\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 80\u001b[39m, in \u001b[36mrun_pipeline\u001b[39m\u001b[34m(address)\u001b[39m\n\u001b[32m     78\u001b[39m activity = get_wallet_activity_table(address)\n\u001b[32m     79\u001b[39m token_transfers = get_token_transfers(address)\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m \u001b[43msave_to_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_transfers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m export_to_csv(summary, activity, token_transfers)\n\u001b[32m     83\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPipeline complete.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36msave_to_db\u001b[39m\u001b[34m(summary_df, activity_df, token_df)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Insert summary row\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m summary_df.iterrows():\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[33;43m        INSERT INTO wallet_summary (\u001b[39;49m\n\u001b[32m     17\u001b[39m \u001b[33;43m            wallet, first_tx_date, last_tx_date, tx_count,\u001b[39;49m\n\u001b[32m     18\u001b[39m \u001b[33;43m            total_eth_sent, total_eth_received, net_et\u001b[39;49m\n\u001b[32m     19\u001b[39m \u001b[33;43m            h,\u001b[39;49m\n\u001b[32m     20\u001b[39m \u001b[33;43m            total_gas_spent, current_eth_balance\u001b[39;49m\n\u001b[32m     21\u001b[39m \u001b[33;43m        ) VALUES (\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\n\u001b[32m     22\u001b[39m \u001b[33;43m    \u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwallet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfirst_tx_date\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlast_tx_date\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtx_count\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtotal_eth_sent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtotal_eth_received\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnet_eth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtotal_gas_spent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcurrent_eth_balance\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Insert activity rows\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m activity_df.iterrows():\n",
            "\u001b[31mSyntaxError\u001b[39m: syntax error at or near \"h\"\nLINE 5:                 h,\n                        ^\n"
          ]
        }
      ],
      "source": [
        "#Save_to_db() and run_pipeline()\n",
        "\n",
        "def save_to_db(summary_df, activity_df, token_df):\n",
        "    \"\"\"Save wallet_summary, wallet_activity and token_transfers DataFrames to PostgreSQL.\"\"\"\n",
        "    conn = get_db_connection()\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    wallet = summary_df[\"wallet\"].iloc[0]\n",
        "    cursor.execute(\"DELETE FROM wallet_summary WHERE wallet = %s\", (wallet,))\n",
        "    cursor.execute(\"DELETE FROM wallet_activity WHERE wallet = %s\", (wallet,))\n",
        "    cursor.execute(\"DELETE FROM token_transfers WHERE from_address = %s OR to_address = %s\", (wallet, wallet))\n",
        "\n",
        "    # Insert summary row\n",
        "    for _, row in summary_df.iterrows():\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO wallet_summary (\n",
        "                wallet, first_tx_date, last_tx_date, tx_count,\n",
        "                total_eth_sent, total_eth_received, net_eth,\n",
        "                total_gas_spent, current_eth_balance\n",
        "            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
        "        \"\"\", (\n",
        "            row[\"wallet\"],\n",
        "            row[\"first_tx_date\"],\n",
        "            row[\"last_tx_date\"],\n",
        "            int(row[\"tx_count\"]),\n",
        "            float(row[\"total_eth_sent\"]),\n",
        "            float(row[\"total_eth_received\"]),\n",
        "            float(row[\"net_eth\"]),\n",
        "            float(row[\"total_gas_spent\"]),\n",
        "            float(row[\"current_eth_balance\"]),\n",
        "        ))\n",
        "\n",
        "    # Insert activity rows\n",
        "    for _, row in activity_df.iterrows():\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO wallet_activity (\n",
        "                wallet, period, tx_count, eth_sent, eth_received, gas_spent\n",
        "            ) VALUES (%s, %s, %s, %s, %s, %s)\n",
        "        \"\"\", (\n",
        "            row[\"wallet\"],\n",
        "            row[\"period\"],\n",
        "            int(row[\"tx_count\"]),\n",
        "            float(row[\"eth_sent\"]),\n",
        "            float(row[\"eth_received\"]),\n",
        "            float(row[\"gas_spent\"]),\n",
        "        ))\n",
        "\n",
        "    # Insert token transfer rows\n",
        "    for _, row in token_df.iterrows():\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO token_transfers (\n",
        "                tx_hash, token_symbol, token_contract,\n",
        "                from_address, to_address, value, timestamp\n",
        "            ) VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
        "        \"\"\", (\n",
        "            row[\"tx_hash\"],\n",
        "            row[\"token_symbol\"],\n",
        "            row[\"token_contract\"],\n",
        "            row[\"from_address\"],\n",
        "            row[\"to_address\"],\n",
        "            float(row[\"value\"]) if row[\"value\"] is not None else None,\n",
        "            row[\"timestamp\"],\n",
        "        ))\n",
        "\n",
        "    conn.commit()\n",
        "    cursor.close()\n",
        "    conn.close()\n",
        "    print(f\"Saved data for wallet {wallet} to PostgreSQL\")\n",
        "\n",
        "\n",
        "\n",
        "def run_pipeline(address):\n",
        "    \"\"\"Fetch wallet data from Alchemy, save to PostgreSQL and export CSVs for Tableau Public.\"\"\"\n",
        "    print(f\"Running pipeline for {address}...\")\n",
        "\n",
        "    summary = get_wallet_summary_table(address)\n",
        "    activity = get_wallet_activity_table(address)\n",
        "    token_transfers = get_token_transfers(address)\n",
        "    save_to_db(summary, activity, token_transfers)\n",
        "    export_to_csv(summary, activity, token_transfers)\n",
        "\n",
        "    print(\"Pipeline complete.\")\n",
        "\n",
        "# Run it\n",
        "run_pipeline(\"0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "84c92a73",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   token_symbol                              token_contract         value\n",
            "12          NOT  0x0027449bf0887ca3e431d263ffdefb244d95b555  1.157921e+41\n",
            "13          NOT  0x0027449bf0887ca3e431d263ffdefb244d95b555  1.157921e+41\n"
          ]
        }
      ],
      "source": [
        "test = get_token_transfers(\"0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045\")\n",
        "print(test[test[\"token_symbol\"] == \"NOT\"][[\"token_symbol\", \"token_contract\", \"value\"]])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
